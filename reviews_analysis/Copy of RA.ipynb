{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hPEuCupGlTK"
      },
      "source": [
        "# Reviews Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRfCt2Y309Cp"
      },
      "source": [
        "change runtime to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up5O4bEkx1xC",
        "outputId": "9515d22c-5110-41de-95f6-0c96b8ae075f"
      },
      "outputs": [],
      "source": [
        "# !nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dPz-zGGG2Lm"
      },
      "source": [
        "# 1. Problem Identification & Goal Formulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peyKesXcHQmU"
      },
      "source": [
        "+ Problem:\n",
        "  - In today's market, numerous services and products fall short of meeting user expectations, necessitating a system that can effectively recommend the highest quality options based on insights from user reviews.\n",
        "\n",
        "+ Goal:\n",
        "  - The primary objective is to develop a machine learning model that can accurately classify user reviews into two distinct categories: `Positive` and `Negative`. Furthermore, the model should identify and prioritize the `most highly recommended` services and products within the `\"Positive\" category`, while discouraging the usage of those falling under the `\"Negative\" category`. This will help users make informed decisions and enhance their overall experience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc9Fcm-pLHZl"
      },
      "source": [
        "# 2. Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PtuuFieN_MyO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZvQthO9-M95",
        "outputId": "80d2d0c4-1d63-43e0-cef2-e4cabad11080"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tbN9p4Ic_FuO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\Projects\\\\RA'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "home= os.getcwd()\n",
        "home"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "venMcEPDbIF7"
      },
      "source": [
        "load train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1zq2CJjz_D3n"
      },
      "outputs": [],
      "source": [
        "train_data= pd.read_csv(f\"{home}/data/train_data/train.csv\", names= ['result', 'title', 'reviews']).head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data= train_data['result'].replace[:100000,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FM3PxnHLNH8E",
        "outputId": "a5f3c7f9-ff69-4b56-bbee-bcc3973741bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>result</th>\n",
              "      <th>title</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Stuning even for the non-gamer</td>\n",
              "      <td>This sound track was beautiful! It paints the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The best soundtrack ever to anything.</td>\n",
              "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Amazing!</td>\n",
              "      <td>This soundtrack is my favorite music of all ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Excellent Soundtrack</td>\n",
              "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
              "      <td>If you've played the game, you know how divine...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   result                                              title  \\\n",
              "0       2                     Stuning even for the non-gamer   \n",
              "1       2              The best soundtrack ever to anything.   \n",
              "2       2                                           Amazing!   \n",
              "3       2                               Excellent Soundtrack   \n",
              "4       2  Remember, Pull Your Jaw Off The Floor After He...   \n",
              "\n",
              "                                             reviews  \n",
              "0  This sound track was beautiful! It paints the ...  \n",
              "1  I'm reading a lot of reviews saying that this ...  \n",
              "2  This soundtrack is my favorite music of all ti...  \n",
              "3  I truly like this soundtrack and I enjoy video...  \n",
              "4  If you've played the game, you know how divine...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AzCZszMRNNlP",
        "outputId": "7f93dd8a-0534-4f94-ba9b-80fe9288f2a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>result</th>\n",
              "      <th>title</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1</td>\n",
              "      <td>Very Not Worth Your Time</td>\n",
              "      <td>The book was wriiten very horribly. I would ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2</td>\n",
              "      <td>Very fun and educational</td>\n",
              "      <td>Trains, shapes and pegs - a winning combinatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1</td>\n",
              "      <td>Ludicrous and silly</td>\n",
              "      <td>I remember getting this book so faintly that t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2</td>\n",
              "      <td>Artistry</td>\n",
              "      <td>I think that the Deodato concerts are very ric...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1</td>\n",
              "      <td>Caution!</td>\n",
              "      <td>These tracks are not the \"original\" versions b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    result                     title  \\\n",
              "95       1  Very Not Worth Your Time   \n",
              "96       2  Very fun and educational   \n",
              "97       1       Ludicrous and silly   \n",
              "98       2                  Artistry   \n",
              "99       1                  Caution!   \n",
              "\n",
              "                                              reviews  \n",
              "95  The book was wriiten very horribly. I would ne...  \n",
              "96  Trains, shapes and pegs - a winning combinatio...  \n",
              "97  I remember getting this book so faintly that t...  \n",
              "98  I think that the Deodato concerts are very ric...  \n",
              "99  These tracks are not the \"original\" versions b...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBo0ttB8bMzp"
      },
      "source": [
        "load test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dAf4F8L9bMaJ"
      },
      "outputs": [],
      "source": [
        "test_data= pd.read_csv(f\"{home}/data/test_data/test.csv\", names= ['result', 'title', 'reviews']).head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data= test_data.iloc[:20000,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pwOkhX9FcZt0",
        "outputId": "548186d9-9aa2-4fd3-d271-bc02515ff010"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>result</th>\n",
              "      <th>title</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>Great CD</td>\n",
              "      <td>My lovely Pat has one of the GREAT voices of h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>One of the best game music soundtracks - for a...</td>\n",
              "      <td>Despite the fact that I have only played a sma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Batteries died within a year ...</td>\n",
              "      <td>I bought this charger in Jul 2003 and it worke...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>works fine, but Maha Energy is better</td>\n",
              "      <td>Check out Maha Energy's website. Their Powerex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Great for the non-audiophile</td>\n",
              "      <td>Reviewed quite a bit of the combo players and ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   result                                              title  \\\n",
              "0       2                                           Great CD   \n",
              "1       2  One of the best game music soundtracks - for a...   \n",
              "2       1                   Batteries died within a year ...   \n",
              "3       2              works fine, but Maha Energy is better   \n",
              "4       2                       Great for the non-audiophile   \n",
              "\n",
              "                                             reviews  \n",
              "0  My lovely Pat has one of the GREAT voices of h...  \n",
              "1  Despite the fact that I have only played a sma...  \n",
              "2  I bought this charger in Jul 2003 and it worke...  \n",
              "3  Check out Maha Energy's website. Their Powerex...  \n",
              "4  Reviewed quite a bit of the combo players and ...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rnNr710RcdQ9",
        "outputId": "9feb8cb7-2b1b-49c6-9e8f-5a821d22fd62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>result</th>\n",
              "      <th>title</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>Don't buy!</td>\n",
              "      <td>First of all, the company took my money and se...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2</td>\n",
              "      <td>Simple, Durable, Fun game for all ages</td>\n",
              "      <td>This is an AWESOME game! Almost everyone know ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2</td>\n",
              "      <td>Review of Kelly Club for Toddlers</td>\n",
              "      <td>For the price of 7.99, this PC game is WELL wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2</td>\n",
              "      <td>SOY UN APASIONADO DEL BOX</td>\n",
              "      <td>Y ESTE LIBRO ESTÁ ESPLÉNDIDO !Lo disfrutas, lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2</td>\n",
              "      <td>Some of the best fiddle playing I have heard i...</td>\n",
              "      <td>This is an excellent album with some great fid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    result                                              title  \\\n",
              "15       1                                         Don't buy!   \n",
              "16       2             Simple, Durable, Fun game for all ages   \n",
              "17       2                  Review of Kelly Club for Toddlers   \n",
              "18       2                          SOY UN APASIONADO DEL BOX   \n",
              "19       2  Some of the best fiddle playing I have heard i...   \n",
              "\n",
              "                                              reviews  \n",
              "15  First of all, the company took my money and se...  \n",
              "16  This is an AWESOME game! Almost everyone know ...  \n",
              "17  For the price of 7.99, this PC game is WELL wo...  \n",
              "18  Y ESTE LIBRO ESTÁ ESPLÉNDIDO !Lo disfrutas, lo...  \n",
              "19  This is an excellent album with some great fid...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM20LyJ-Fgtx"
      },
      "source": [
        "unique classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "HhY7tBKZFkuw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 1], dtype=int64)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels= train_data['result'].unique()\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXU4LBzZLNsT"
      },
      "source": [
        "# 3. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isLN_Z4NOIRN"
      },
      "source": [
        "drop missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "t8aJp2IUPI0T"
      },
      "outputs": [],
      "source": [
        "train_data.dropna(inplace=True)\n",
        "test_data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuHOV_n7AKep",
        "outputId": "f342221a-28e9-469d-ae78-85c25f7c9841"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "result     0\n",
              "title      0\n",
              "reviews    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ihkIpoDcox9",
        "outputId": "e0a5cb5d-446c-419c-90eb-3f5a122683dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "result     0\n",
              "title      0\n",
              "reviews    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqGhKcWbPfkQ"
      },
      "source": [
        "drop duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WnW-RI75Ph6i"
      },
      "outputs": [],
      "source": [
        "train_data.drop_duplicates(inplace=True)\n",
        "test_data.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDToOtQqQD1m"
      },
      "source": [
        "we have column `title` not necessary, so we drop it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0RVhcFpzRx36"
      },
      "outputs": [],
      "source": [
        "train_data.drop('title', axis=1, inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ajJ_N3Hoc476"
      },
      "outputs": [],
      "source": [
        "test_data.drop('title', axis=1, inplace= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7OCRO9rSh-5"
      },
      "source": [
        "now, we will start the preprcessing step for NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knOHcHRIS78J"
      },
      "source": [
        "Noise Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "E5wdULfNTAn1"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "# nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA7CUERvTR44"
      },
      "source": [
        "show stop words list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK7mjCtATRhN",
        "outputId": "85d736e5-008b-4973-e2d3-dade363c58fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "stop_words= stopwords.words('english')\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-VP7VPeTjx2"
      },
      "source": [
        "excluding some useful words from stop words list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-zR5f-jTsGW",
        "outputId": "bd81199b-6f75-425d-9428-09385a1af18e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'hasn', 'ma', 'mightn', 'shan', \"shan't\"]\n"
          ]
        }
      ],
      "source": [
        "excluding= ['againts','no' ,'not', 'don', \"don't\", 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn',\n",
        "            \"didn't\",'doesn', \"doesn't\", 'hadn', \"hadn't\", 'has', \"hasn't\", 'haven', \"haven't\", 'isn',\n",
        "            \"isn't\", 'might', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shouldn', \"shouldn't\",\n",
        "            'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "\n",
        "stop_words= [word for word in stop_words if word not in excluding]\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKt1S_UdU0--"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DBfSHdnEU7mb"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx8SOuuRVU9s"
      },
      "source": [
        "Word normalization with `PorterStemmer` and `WordNetLemmatizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cWZYCZu6VC-9"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "stemmer= PorterStemmer()\n",
        "lemmatizer= WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDlzb-in1SjD"
      },
      "source": [
        "Define funcation preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Y3NydhM4V73d"
      },
      "outputs": [],
      "source": [
        "def preprocessing(text):\n",
        "  cleaned_texts= []\n",
        "  sentences = sent_tokenize(text)\n",
        "\n",
        "  # loop on each sentence\n",
        "  for sent in sentences:\n",
        "    filtered_sent= []\n",
        "    tokens= word_tokenize(sent.lower())\n",
        "\n",
        "    # loop on each word from sentence\n",
        "    for token in tokens:\n",
        "      # check if it's not numeric and its length > 2 and not in stop words\n",
        "      if (not token.isnumeric()) and (len(token) > 2) and (token not in stop_words):\n",
        "        stemmed_token = stemmer.stem(token)\n",
        "        lemmatized_token = lemmatizer.lemmatize(stemmed_token)\n",
        "        filtered_sent.append(lemmatized_token)\n",
        "\n",
        "    # convert tokens to sentence\n",
        "    cleaned_sent= \" \".join(filtered_sent)\n",
        "    cleaned_texts.append(cleaned_sent)\n",
        "\n",
        "  # Combine all cleaned sentences into a single string\n",
        "  preprocessed_text = \" \".join(cleaned_texts)\n",
        "  return preprocessed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zYpV3zpIAvJ6",
        "outputId": "cacf97d6-23fa-497e-dc4f-943c03f0c1d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data['reviews'][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qtJyBV0zAfpy",
        "outputId": "2d5a9094-6ce2-463f-dadd-0a2b8cc11cfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'bought charger jul work design nice conveni howev year batteri would not hold charg might well get alkalin dispos look elsewher charger come batteri better stay power'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = preprocessing(test_data['reviews'][2])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OhZJTXKUe0hK"
      },
      "outputs": [],
      "source": [
        "X_train= train_data['reviews'].values\n",
        "y_train= train_data['result'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_msGBS2aeytO"
      },
      "outputs": [],
      "source": [
        "X_test= test_data['reviews'].values\n",
        "y_test= test_data['result'].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot\n",
        "ax= sns.countplot(x=train_data['result'],\n",
        "                  data=train_data)\n",
        "\n",
        "for p in ax.patches: # bars\n",
        "    '''\n",
        "    get_bbox(): return bounding box of the bar, \n",
        "    get_points(): returns the coordinates of the four corners of the bounding box.\n",
        "    '''\n",
        "    x= p.get_bbox().get_points()[:,0] # extract the x-coordinates of the four corners of the bar rectangle\n",
        "    y= p.get_bbox().get_points()[1,1] # extract the y-coordinate of the top-right corner\n",
        "    ax.annotate(f'{y:.0f}', (x.mean(), y), ha='center',va='bottom') # text on top bar\n",
        "    \n",
        "plt.title(\"Reviews are balance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2zVrql5Lfc9"
      },
      "source": [
        "# 5. Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CYNKXyJILje-"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEkrVSD184Fg"
      },
      "source": [
        "Define the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0lB29tz77luA"
      },
      "outputs": [],
      "source": [
        "pipeline= Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(preprocessor= preprocessing, tokenizer=word_tokenize)),\n",
        "    ('nb', MultinomialNB())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjzwzpwO9JLJ"
      },
      "source": [
        "Define a grid of hyperparameters for the MultinomialNB model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VTcD6Apq9K75"
      },
      "outputs": [],
      "source": [
        "param_grid_nb= {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
        "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
        "    'tfidf__min_df': [1, 2, 3],\n",
        "    'nb__alpha': [0.1, 0.01, 0.001]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2rtEFWzAGyw"
      },
      "source": [
        "Create GridSearchCV instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3JLiHQEIAJPz"
      },
      "outputs": [],
      "source": [
        "grid_search= GridSearchCV(pipeline,\n",
        "                          param_grid= param_grid_nb,\n",
        "                          cv= 5,\n",
        "                          return_train_score= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEgYF5wDBpEM"
      },
      "source": [
        "# 5. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "cFgIqpZjI8yh",
        "outputId": "da6a0b9b-6caa-4d1e-f95b-fcc13907c556"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN5KGVgKI5m8",
        "outputId": "3d8fab96-362f-49b7-f26a-6114099614db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55BeG0idA_m8"
      },
      "source": [
        "Fit the GridSearchCV on your training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOtri6SxBBAU",
        "outputId": "3ce8f074-0719-4b05-bc95-45ee2c9a68b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "c:\\Users\\CENTER_ELRahama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                                        TfidfVectorizer(preprocessor=&lt;function preprocessing at 0x000001F39C9BD6C0&gt;,\n",
              "                                                        tokenizer=&lt;function word_tokenize at 0x000001F3251FE3E0&gt;)),\n",
              "                                       (&#x27;nb&#x27;, MultinomialNB())]),\n",
              "             param_grid={&#x27;nb__alpha&#x27;: [0.1, 0.01, 0.001],\n",
              "                         &#x27;tfidf__max_df&#x27;: [0.5, 0.75, 1.0],\n",
              "                         &#x27;tfidf__min_df&#x27;: [1, 2, 3],\n",
              "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2), (2, 2)]},\n",
              "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                                        TfidfVectorizer(preprocessor=&lt;function preprocessing at 0x000001F39C9BD6C0&gt;,\n",
              "                                                        tokenizer=&lt;function word_tokenize at 0x000001F3251FE3E0&gt;)),\n",
              "                                       (&#x27;nb&#x27;, MultinomialNB())]),\n",
              "             param_grid={&#x27;nb__alpha&#x27;: [0.1, 0.01, 0.001],\n",
              "                         &#x27;tfidf__max_df&#x27;: [0.5, 0.75, 1.0],\n",
              "                         &#x27;tfidf__min_df&#x27;: [1, 2, 3],\n",
              "                         &#x27;tfidf__ngram_range&#x27;: [(1, 1), (1, 2), (2, 2)]},\n",
              "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(preprocessor=&lt;function preprocessing at 0x000001F39C9BD6C0&gt;,\n",
              "                                 tokenizer=&lt;function word_tokenize at 0x000001F3251FE3E0&gt;)),\n",
              "                (&#x27;nb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(preprocessor=&lt;function preprocessing at 0x000001F39C9BD6C0&gt;,\n",
              "                tokenizer=&lt;function word_tokenize at 0x000001F3251FE3E0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('tfidf',\n",
              "                                        TfidfVectorizer(preprocessor=<function preprocessing at 0x000001F39C9BD6C0>,\n",
              "                                                        tokenizer=<function word_tokenize at 0x000001F3251FE3E0>)),\n",
              "                                       ('nb', MultinomialNB())]),\n",
              "             param_grid={'nb__alpha': [0.1, 0.01, 0.001],\n",
              "                         'tfidf__max_df': [0.5, 0.75, 1.0],\n",
              "                         'tfidf__min_df': [1, 2, 3],\n",
              "                         'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
              "             return_train_score=True)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgNgyTJ0Cq9G"
      },
      "source": [
        "params for number of iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "bZHunXjdCsiF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'nb__alpha': 0.1, 'tfidf__max_df': 0.5, 'tfid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'nb__alpha': 0.1, 'tfidf__max_df': 0.5, 'tfid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'nb__alpha': 0.1, 'tfidf__max_df': 0.5, 'tfid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'nb__alpha': 0.1, 'tfidf__max_df': 0.5, 'tfid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'nb__alpha': 0.1, 'tfidf__max_df': 0.5, 'tfid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>{'nb__alpha': 0.001, 'tfidf__max_df': 1.0, 'tf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>{'nb__alpha': 0.001, 'tfidf__max_df': 1.0, 'tf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>{'nb__alpha': 0.001, 'tfidf__max_df': 1.0, 'tf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>{'nb__alpha': 0.001, 'tfidf__max_df': 1.0, 'tf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>{'nb__alpha': 0.001, 'tfidf__max_df': 1.0, 'tf...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               params\n",
              "0   {'nb__alpha': 0.1, 'tfidf__max_df': 0.5, 'tfid...\n",
              "1   {'nb__alpha': 0.1, 'tfidf__max_df': 0.5, 'tfid...\n",
              "2   {'nb__alpha': 0.1, 'tfidf__max_df': 0.5, 'tfid...\n",
              "3   {'nb__alpha': 0.1, 'tfidf__max_df': 0.5, 'tfid...\n",
              "4   {'nb__alpha': 0.1, 'tfidf__max_df': 0.5, 'tfid...\n",
              "..                                                ...\n",
              "76  {'nb__alpha': 0.001, 'tfidf__max_df': 1.0, 'tf...\n",
              "77  {'nb__alpha': 0.001, 'tfidf__max_df': 1.0, 'tf...\n",
              "78  {'nb__alpha': 0.001, 'tfidf__max_df': 1.0, 'tf...\n",
              "79  {'nb__alpha': 0.001, 'tfidf__max_df': 1.0, 'tf...\n",
              "80  {'nb__alpha': 0.001, 'tfidf__max_df': 1.0, 'tf...\n",
              "\n",
              "[81 rows x 1 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(grid_search.cv_results_)[['params']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNvEKsqMC_5o"
      },
      "source": [
        "Best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "tL1jb7JFDDhz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'nb__alpha': 0.1,\n",
              " 'tfidf__max_df': 0.5,\n",
              " 'tfidf__min_df': 1,\n",
              " 'tfidf__ngram_range': (1, 2)}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tts7zLt-DGJN"
      },
      "source": [
        "Best score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "62uZs9QuDPVb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'78%'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f\"{round(grid_search.best_score_*100)}%\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNZ9hYoFBKiw"
      },
      "source": [
        " Get the best estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "kAyNB_vyBMS5"
      },
      "outputs": [],
      "source": [
        "best_pipline= grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhEoIwv0LxK0"
      },
      "source": [
        "# 6. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "LPb71gAyD8s0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtNE4cS8BZwi"
      },
      "source": [
        " Now you can use the best_pipeline for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "uKNa9IxYL0FS"
      },
      "outputs": [],
      "source": [
        "y_pred= best_pipline.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frGF6NKHEmeb"
      },
      "source": [
        "accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "EUV4umzIEBnt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 85%\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {round(accuracy*100)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAAuXn5LEyfu"
      },
      "source": [
        "confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "NSuqESBrE0R7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 7,  2],\n",
              "       [ 1, 10]], dtype=int64)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPCGfj-9FAha"
      },
      "source": [
        "# 7. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "RVrsI2PxKuKY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYaE1FpYFHrE"
      },
      "source": [
        "Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "g3r18XPaFJ3F"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (8,6))\n",
        "sns.heatmap(cm,\n",
        "            xticklabels=labels,\n",
        "            yticklabels=labels,\n",
        "            annot=True,\n",
        "            cmap='Blues',\n",
        "            fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p9EKEZTL0kJ"
      },
      "source": [
        "# 7. Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ziyNo7ErF_Yk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['d:\\\\Projects\\\\RA/models/pps_tfidf_nb.joblib']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "model_path = f'{home}/models/pp_tfidf_nb_85.joblib'\n",
        "joblib.dump(best_pipline, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "s-NUJq0BcwMz"
      },
      "outputs": [],
      "source": [
        "model= joblib.load(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict([\"hello it's good, i want to buy it\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
